"""
MediaPipe + LSTM ëª¨ë¸ ë¡œë”
Sign_Language_Translation í”„ë¡œì íŠ¸ ì°¸ê³ 
ì›ë³¸ í”„ë¡œì íŠ¸ì˜ êµ¬ì¡°ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©
"""
import os
import cv2
import numpy as np
import mediapipe as mp
import tensorflow as tf
from pathlib import Path
from typing import List, Optional
from modules.holistic_module import HolisticDetector
from modules.utils import Vector_Normalization

class MediaPipeModelLoader:
    """
    MediaPipe Holistic + LSTM ëª¨ë¸ ë¡œë”
    31ê°œ í•œê¸€ ììŒ/ëª¨ìŒ ì¸ì‹
    """
    def __init__(self, model_path: str = None, classes_path: str = None):
        """
        ëª¨ë¸ ë¡œë” ì´ˆê¸°í™”
        
        Args:
            model_path: TensorFlow Lite ëª¨ë¸ íŒŒì¼ ê²½ë¡œ (.tflite)
            classes_path: í´ë˜ìŠ¤ ì´ë¦„ íŒŒì¼ ê²½ë¡œ (31ê°œ ììŒ/ëª¨ìŒ)
        """
        base_dir = Path(__file__).parent
        
        # ê¸°ë³¸ ëª¨ë¸ ê²½ë¡œ
        self.model_path = model_path or str(base_dir / "model.tflite")
        self.classes_path = classes_path or str(base_dir / "korean_jamo.txt")
        
        # MediaPipe Holistic ì´ˆê¸°í™” (ì›ë³¸ í”„ë¡œì íŠ¸ì™€ ë™ì¼)
        self.detector = HolisticDetector(min_detection_confidence=0.3)
        
        # LSTM ëª¨ë¸
        self.interpreter = None
        self.input_details = None
        self.output_details = None
        
        # 31ê°œ í•œê¸€ ììŒ/ëª¨ìŒ í´ë˜ìŠ¤ (ì›ë³¸ í”„ë¡œì íŠ¸ ìˆœì„œ)
        self.classes = self._load_classes()
        
        # ì‹œí€€ìŠ¤ ë²„í¼ (LSTM ì…ë ¥ìš©)
        self.sequence_buffer = []
        self.sequence_length = 10  # ì›ë³¸ í”„ë¡œì íŠ¸ëŠ” 10
        
        self._loaded = False
        
        # ëª¨ë¸ ë¡œë“œ ì‹œë„
        try:
            self.load_model()
        except Exception as e:
            print(f"âš ï¸ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ - MediaPipeëŠ” ì‚¬ìš© ê°€ëŠ¥í•˜ì§€ë§Œ LSTM ëª¨ë¸ ì—†ìŒ: {e}")
            print("ğŸ’¡ MediaPipeë§Œìœ¼ë¡œë„ hand landmarks ì¶”ì¶œì€ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
            self._loaded = False
    
    def _load_classes(self) -> List[str]:
        """31ê°œ í•œê¸€ ììŒ/ëª¨ìŒ í´ë˜ìŠ¤ ë¡œë“œ (ì›ë³¸ í”„ë¡œì íŠ¸ ìˆœì„œ)"""
        # ì›ë³¸ í”„ë¡œì íŠ¸ì˜ ìˆœì„œëŒ€ë¡œ
        default_classes = [
            'ã„±', 'ã„´', 'ã„·', 'ã„¹', 'ã…', 'ã…‚', 'ã……', 'ã…‡', 'ã…ˆ', 'ã…Š', 'ã…‹', 'ã…Œ', 'ã…', 'ã…',
            'ã…', 'ã…‘', 'ã…“', 'ã…•', 'ã…—', 'ã…›', 'ã…œ', 'ã… ', 'ã…¡', 'ã…£',
            'ã…', 'ã…’', 'ã…”', 'ã…–', 'ã…¢', 'ã…š', 'ã…Ÿ'
        ]
        
        # íŒŒì¼ì—ì„œ ë¡œë“œ ì‹œë„
        if os.path.exists(self.classes_path):
            try:
                with open(self.classes_path, 'r', encoding='utf-8') as f:
                    classes = [line.strip() for line in f.readlines() if line.strip()]
                if len(classes) == 31:
                    return classes
            except Exception as e:
                print(f"í´ë˜ìŠ¤ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨, ê¸°ë³¸ ëª©ë¡ ì‚¬ìš©: {e}")
        
        return default_classes
    
    def load_model(self):
        """TensorFlow Lite ëª¨ë¸ ë¡œë“œ"""
        if self._loaded:
            return True
        
        if not os.path.exists(self.model_path):
            raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.model_path}")
        
        # TensorFlow Lite ì¸í„°í”„ë¦¬í„° ë¡œë“œ
        self.interpreter = tf.lite.Interpreter(model_path=self.model_path)
        self.interpreter.allocate_tensors()
        
        # ì…ë ¥/ì¶œë ¥ ìƒì„¸ ì •ë³´
        self.input_details = self.interpreter.get_input_details()
        self.output_details = self.interpreter.get_output_details()
        
        self._loaded = True
        print(f"âœ… LSTM ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {self.model_path}")
        print(f"   í´ë˜ìŠ¤ ìˆ˜: {len(self.classes)}")
        return True
    
    def is_loaded(self) -> bool:
        """ëª¨ë¸ì´ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸"""
        return self._loaded
    
    def get_detector(self):
        """MediaPipe Holistic Detector ê°ì²´ ë°˜í™˜"""
        return self.detector
    
    def get_classes(self) -> List[str]:
        """í´ë˜ìŠ¤ ëª©ë¡ ë°˜í™˜"""
        return self.classes
    
    def extract_landmarks(self, frame: np.ndarray) -> Optional[np.ndarray]:
        """
        MediaPipe Holisticì„ ì‚¬ìš©í•˜ì—¬ ì˜¤ë¥¸ì† ëœë“œë§ˆí¬ ì¶”ì¶œ ë° ë²¡í„°/ê°ë„ ê³„ì‚°
        ì›ë³¸ í”„ë¡œì íŠ¸ì˜ webcam_test_model_tflite.pyì™€ ë™ì¼í•œ ë°©ì‹
        
        Args:
            frame: BGR ì´ë¯¸ì§€ í”„ë ˆì„
            
        Returns:
            feature ë²¡í„° (None if ì†ì´ ê°ì§€ë˜ì§€ ì•ŠìŒ)
        """
        # Holistic ì²˜ë¦¬
        self.detector.findHolistic(frame, draw=False)
        right_hand_lmList, right_hand_landmarks = self.detector.findRighthandLandmark(frame)
        
        if right_hand_landmarks is None:
            return None
        
        # ì˜¤ë¥¸ì† ëœë“œë§ˆí¬ë¥¼ joint ë°°ì—´ë¡œ ë³€í™˜ (21ê°œ í¬ì¸íŠ¸, x, y ì¢Œí‘œë§Œ)
        joint = np.zeros((21, 2))
        for j, lm in enumerate(right_hand_landmarks.landmark):
            joint[j] = [lm.x, lm.y]
        
        # ë²¡í„° ì •ê·œí™” (ì›ë³¸ í”„ë¡œì íŠ¸ì™€ ë™ì¼)
        vector, angle_label = Vector_Normalization(joint)
        
        # feature ë²¡í„° ìƒì„± (ì›ë³¸ í”„ë¡œì íŠ¸ì™€ ë™ì¼)
        d = np.concatenate([vector.flatten(), angle_label.flatten()])
        
        return d
    
    def predict(self, feature: np.ndarray) -> tuple:
        """
        LSTM ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡
        
        Args:
            feature: feature ë²¡í„° (ë²¡í„° + ê°ë„)
            
        Returns:
            (prediction, confidence) íŠœí”Œ
        """
        if not self._loaded or self.interpreter is None:
            return "", 0.0
        
        # ì‹œí€€ìŠ¤ ë²„í¼ì— ì¶”ê°€
        self.sequence_buffer.append(feature)
        
        # ì‹œí€€ìŠ¤ ê¸¸ì´ ìœ ì§€
        if len(self.sequence_buffer) > self.sequence_length:
            self.sequence_buffer.pop(0)
        
        # ì¶©ë¶„í•œ í”„ë ˆì„ì´ ëª¨ì´ì§€ ì•Šì•˜ìœ¼ë©´ ì˜ˆì¸¡ ì•ˆ í•¨
        if len(self.sequence_buffer) < self.sequence_length:
            return "", 0.0
        
        # ì‹œí€€ìŠ¤ ë°ì´í„° ì¤€ë¹„ (ì›ë³¸ í”„ë¡œì íŠ¸ì™€ ë™ì¼)
        input_data = np.expand_dims(
            np.array(self.sequence_buffer[-self.sequence_length:], dtype=np.float32), 
            axis=0
        )
        
        # ëª¨ë¸ ì…ë ¥
        self.interpreter.set_tensor(self.input_details[0]['index'], input_data)
        self.interpreter.invoke()
        
        # ì˜ˆì¸¡ ê²°ê³¼
        output_data = self.interpreter.get_tensor(self.output_details[0]['index'])
        predictions = output_data[0]  # (31,)
        
        # ê°€ì¥ ë†’ì€ ì‹ ë¢°ë„ì˜ í´ë˜ìŠ¤
        class_id = int(np.argmax(predictions))
        confidence = float(predictions[class_id])
        
        if class_id < len(self.classes):
            return self.classes[class_id], confidence
        
        return "", 0.0
    
    def reset_sequence(self):
        """ì‹œí€€ìŠ¤ ë²„í¼ ì´ˆê¸°í™”"""
        self.sequence_buffer = []
